\documentclass[a4paper,12pt]{article}
\usepackage[english]{babel}
\usepackage{graphicx}
\graphicspath{ {images/} }
\usepackage[font=it,labelfont=bf]{caption}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{varwidth}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{subcaption}
\usepackage{float}
\usepackage{titlesec}
\usepackage{cleveref}
\usepackage{cite}
\usepackage{url}
\usepackage{harvard}
\usepackage{thm-restate}
\usepackage[space]{grffile}
\usepackage{multicol}
\usepackage{changepage}

\citationmode{abbr}


\linespread{1.3}

\captionsetup[subfigure]{subrefformat=simple,labelformat=simple}
\renewcommand\thesubfigure{(\alph{subfigure})}

\setcounter{secnumdepth}{4}
\newcommand{\myparagraph}[1]{\paragraph*{#1}\mbox{}\\}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{defin}{Definition}
\newtheorem*{rquestion}{Question}
\newtheorem{subquestion}{Sub-Question}
\newcommand{\mydef}[3]{
\begin{defin}
\textsc{#1}

Given: #2

Question: #3
\end{defin}}

\newcommand{\bigO}[1]{$\mathcal{O}$($#1$)}
\newcommand{\bigOs}[1]{$\mathcal{O^*}$($#1$)}
\newcommand{\NP}{$\mathcal{NP}$}
\newcommand{\acco}[1]{\{ #1 \}}

\newcommand{\vecarr}[3]{\overset{#2}{\overrightarrow{#1}}}

%Door deze regel springt de eerste regel van
%elke alinea niet meer steeds een stukje in.
%\setlength{\parskip}{\baselineskip}
%Door deze regel wordt tussen de alinea's steeds
%een regel overgeslagen.

%\setlength{\columnseprule}{1pt}
%\def\columnseprulecolor{\color{blue}}

\newcommand{\algorithmicbreak}{\textbf{break}}
\newcommand{\Break}{\State \algorithmicbreak}



\begin{document}
\title{Simulation and Optimization of Offshore Renewable Energy Arrays for Minimal Life-Cycle Costs \\
\large Second Year Report}
\author{Robin Kuipers \\[1cm] Supervisors: \\ Kerem Akartunali \\ Euan Barlow\\[2cm] University of Strathclyde \\ Strathclyde Business School \\ {\small Glasgow, Scotland}}
\date{October, 2020}

\maketitle

\pagebreak

\begin{abstract}
This report aims to give a detailed overview of the research progress I made between January 2020 and September 2020, which is the time between the completion of the first yearly review and the start of the second yearly review of this PhD project into logistical decisions regarding offshore wind farms. It will quickly recap the progress made in the first year, and then detail the progress made in the second year, which primarily focused on developing and implementing models for optimization problems related to topic. The report also discusses future work, and what the next steps are. 
\end{abstract}

\pagebreak

\tableofcontents

\pagebreak

\section{Introduction}\label{ss:omtrp}
For the past two years, I have been researching logistics related to offshore windfarm projects; the installation, maintenance, and decommissioning of windfarms in various seas and oceans, primarily the North Sea. The installation and decommissioning projects (at the start and end of the windfarm's lifespan respectively) can often take up to several years, and the lifespan of such farms is usually between 20 and 30 years, over which maintenance has to be done. For these projects, expensive vessels have to be used, the rent of which is often upwards of \pounds 100.000 per day \cite{barlow2014support}, hence a project with multiple vessels over many months can cost upwards of \pounds 100 million \cite{kaiser2010offshore}. Therefore, even small improvements to the schedules can save significant amounts of money.

The complexity with these logistics comes from various factors, the first being the severe impact that weather conditions can have on when operational tasks can be completed. These projects take place on open sea, where weather can often be rougher than on land. In addition, the high-tech vessels are performing operations on large industrial constructions, hence there is a limited range of allowed wind speeds and wave heights. Another factor which can further limit possible schedules is the inflexibility involved in vessel chartering (renting), since vessels of the required caliber cannot be chartered on short notice, making adaptive in-the-moment scheduling is impossible. This means we will have to make decisions significantly in advance, and run the risk of chartering vessels in periods where they might not be able to complete their tasks due to the weather conditions. 

This report will detail the research progress I have made since the completion of my first yearly review, which (due to scheduling issues and delays) was only completed in January 2020. Further on in this section, I will recap the specific parts of this problem that I am looking at (\Cref{ss:prob}), and which research questions I initially posed (\Cref{ss:quest}). Then \Cref{s:know} through  \Cref{s:addit} will talk about the work I have been doing since the last review. Respectively, these sections are about the knowledge gaps I closed, the models I have developed, how I have implemented them, and all additional activities I have taken part in. Finally, \Cref{s:next} will discuss the next steps for this project. 

\subsection{Problem description} \label{ss:prob}
This research looks at offshore windfarms (OWFs) and the scheduling decisions made over the entire life-cycle of such an OWF. I will focus on the type of windfarms currently being build in the North Sea \cite{ruk2017,barlow2018mixed}. These windfarms generally consist of up to 150 Wind Turbine Generators (WTGs) and the farms we focus on are located in roughly 50+ kilometers off the coast. The specific duration of each phase of the life-cycle depends on the specific windfarm, but to give the reader some idea of the timescales involved: A typical life-cycle would consist of roughly 2-3 yeas of installation, 20-30 years in which the WTGs generate energy and need to be maintained, and then another 2-3 years in which the turbines are decommissioned. These turbines are large structures that will need to be transported and installed by specialized and expensive vessels, leading to large costs over these years. 

\bigskip

In the literature these three phases are commonly treated separately. Both the installation and decommission phases have similar structures; a fixed set of tasks that needs to be completed as quickly or as profitably as possible. Focusing on cost over speed might lead to a different schedule, as some decisions might slow down the overall project but lead to individual turbines being operational earlier, from which point it can start generating energy and income. Commonly there will be contractual or legal deadlines on installation and decommission, setting dates at which the OWF should be fully or partially operational, or completely decommissioned. A key difference between the installation and decommission phase are that in the installation phase minimizing cost will help reach the deadlines; ideally the installation is completed as soon as possible, as income will be generated by each completed turbine. For decommission this is not the case; if decommission starts later turbines will generate income for longer, but it will be harder to reach the deadlines. 

The maintenance phase has an entirely different structure from the other two phases. There will be a small set of fixed tasks, since there are legal requirements on minimum amount of maintenance that needs to be done, but this will not be the bulk of the work performed during this phase. A maintenance strategy will need to be formed that determines when turbines will be visited. These visits can be at predetermined moments, or after a turbine fails, or sometimes even right before a turbine is predicted to fail (based on sensor data). An optimal strategy will often use a combination of these types of visits in order to minimize cost, accounting for both the cost of repairs and the amount of income missed due to failures and downtime during maintenance. An additional difference during the maintenance phase is that tasks will often be smaller than the tasks in the other phases. During installation and decommission entire turbines need to be transported and worked on, often requiring very specific and expensive vessels. Conversely during maintenance many smaller repairs can often be done by simply sending engineers over and all you need is a crew transport vessel. This is not the case for every maintenance task as larger repairs and replacements will sometimes need to happen, but it will still hold for many small tasks.

\bigskip

Each of these three phases is subject to stochastic elements, the weather conditions being a major factor to take into account. In addition to the weather possibly restricting which tasks can be performed at any given time, it plays another factor during the maintenance phase. Strong winds also increase the energy output of the turbines, making it extra beneficial to have all turbines up and running before periods of strong winds. Other than the weather, task durations have an inherently uncertain factor, and turbine failures are also difficult to predict. All this together means that uncertain factors can have an immense impact on the overall costs of the project. For this reason robustness is often a metric to be taken into account as well. It might be in the operators best interest to work a less intensive schedule if it reduces the chances of large delays.

\subsection{Research questions}\label{ss:quest}
In this PhD project my goal is to look at scheduling during the entire life-cycle of an OWF. As far as we are aware, this has not been done in the literature, which indicated there may be optimizations and new insights to be found here. Therefore my primary research question is:

\begin{restatable}{rquestion}{rquest}
Can considering the entirety of the life-cycle of an Offshore Wind Farm, and how each of the phases interact, improve logistical decision making on these projects?
\label{rquest}
\end{restatable}

It is clear that a primary reason for splitting the project into phases is that the problem becomes more manageable, and there is generally no need to make all scheduling decisions at the start of the project. There is no point in scheduling the entire decommission phase at the time of installation, as over the 20-30 year lifespan of the windfarm the available vessels will likely change. However, treating the phases entirely separately misses the interactions between the phases. This interaction exists within the real world, and if the literature ignores it this creates a divide between academia and the real world. For that reason I want to investigate these interactions.

\bigskip

The first type of interaction takes place when two phases are active at the same time; after the first turbines have completed installation they potentially need maintenance, while installation continues on the rest of the turbines. The reverse effect takes place when decommission starts, as it does not start at the same time for every turbine. During this time, the phases share resources and could potentially hinder each other (when the same port is used for different vessels servicing different phases). On the other hand, if attention is payed this sharing of resources could be beneficial. Some installation tasks require smaller vessels that can also be used for maintenance operations, and some maintenance operations use larger vessels more commonly used for installation tasks. Therefore paying attention to this overlap period could both help reduce obstacles and create new benefits from this interaction. 

The second type of interaction is the long-term effect scheduling decisions might have. If the installation is looked at in isolation a schedule might be produced in which the completion time of the first and the last turbine is years apart; this might have an affect on their wear and chance to fail over the course of the maintenance phase. This in turn might also lead to those first-installed turbines being decommissioned first as well. Since decisions made during the installation phase might still influence events long after installation is complete, these long term effects might also influence the decision in the first place. For that reason this interaction can be looked at from two perspectives; early decisions that are influenced by their long-term effects, and later decisions that are influenced by decisions made in earlier phases. 

These interactions bring me to the sub-questions of my research:

\begin{restatable}{subquestion}{sqa}
\label{sqa}
Can considering how phases in the life-cycle of a windfarm overlap and share resources improve logistical decision making on these projects?
\end{restatable}

\begin{restatable}{subquestion}{sqb}
\label{sqb}
Can simulating the entire life-cycle of a windfarm provide useful data to base logistical decisions on in the later phases of these projects?
\end{restatable}

\begin{restatable}{subquestion}{sqc}
\label{sqc}
Can considering the long-term effects of logistical decisions early on in the life-cycle of a windfarm improve these decisions? 
\end{restatable}

\pagebreak

\section{Closing knowledge gaps}\label{s:know}
During my first yearly review it was remarked that most of my reading up to that point focused on either methodology or installation projects, and there were gaps concerning the other two phases, primarily maintenance. Over the past months I have worked to close these gaps, and I consistently updated the literature review as I gained knowledge. This section will show the highlights of that updated literature review, and I will give some closing thoughts on these new insights at the end. 

\subsection{The maintenance phase} \label{ss:maint}
%OG CHECKED: Shafiee, Survey and Categorisation
In \cite{shafiee2015maintenance} the different topics that fall under maintenance are divided into three timescales (echelons):

\begin{enumerate}
\item Strategic: Long term, over the lifespan of an OWF
\begin{itemize}
\item Wind farm design for reliability
\item Location/Capacity of maintenance accommodations
\item Maintenance strategy selection
\item Outsourcing decisions
\end{itemize}
\item Tactical: Medium term, between 1 and 5 years
\begin{itemize}
\item Spare parts management
\item Maintenance support organization
\item Purchasing/leasing decisions
\end{itemize}
\item Operational: Short term, day to day
\begin{itemize}
\item Maintenance scheduling
\item Routing of maintenance vessels
\item Performance measurement
\end{itemize}
\end{enumerate}

Decisions within the strategic echelon are found to have the biggest impact on the costs of operations, which makes sense as they affect the largest amount of time. However each of these echelons include important decisions that will have to be made for the maintenance of the sites. Besides providing this framework to categorize research, they also highlight which areas appear most thoroughly researched, and identify some unexplored areas. Potentially due to their large impact, the topics within the strategic echelon have received most attention, while the topics in the operational echelon received least. The writers indicate they these shorter term areas might hold unexplored potential for future research. 

For my research the most relevant topics are Maintenance strategy selection and maintenance scheduling. These are categorized in opposite echelons, but considering my research focus this makes sense. I am looking at reducing lifetime costs, which clearly falls in the strategic echelon. Specific ideas related to this are considering the long-term impact of decisions and considering historical data from the windfarm. However in order to reduce these costs I am also looking at specific stretches of time within the lifetime, such as when the maintenance phase overlaps with the installation or decommission phases, and specific small-scale decisions made within these stretches of time. This focus clearly falls within the operational echelon, which means different aspects of my research fall within different echelons. 

\bigskip

%OG CHECKED: Dinwoodie paragraph
%Availability
In \cite{dinwoodie2012analysis} an attempt is made to analyse the availability of OWFs. It is observed that the availability of offshore farms is much lower than that of onshore farms; currently offshore availability is around 80\%, while onshore this is 97\%. Various future scenarios are simulated to investigate which measures are likely to improve availability. It is found that increasing vessel operability to allow a higher significant wave height will greatly increase availablity, but realistically it will remain significantly below onshore availability. It is posited this can only be improved with improvement of the components to lower their failure rates, but an 8-fold improvement is required to achieve the same level of availability as onshore. 

%Maintenance Strategies
In another paper \cite{dinwoodie2014operational} the same researchers focus on comparing operational strategies. They consider 4 approaches: 

\begin{itemize}
\item Annual charter, where maintenance operations take place at predetermined times
\item Fix on fail, where repairs are made as soon as any failures are detected
\item Batch repair, where repairs are done after a fixed number of failures is detected
\item Purchase, where a vessel is purchased rather than rented
\end{itemize}

In their research they find the latter three strategies to be close together in costs while the Annual charter strategy lags behind. Which of these three strategies performs best depends on scenario specifics such as fluctuations in vessel costs, the value of energy, and specific failure rates. Each of the strategies also has inherent characteristics that the operator might have preferences in, such as the purchase strategy having much higher costs up front, but lower operational costs. 

An issue with this paper is that mixing of strategies is only very briefly discussed, while this is often beneficial and commonly discussed in the literature. For example, in batch repair, if the batch size is set to 5 failures and for an extended period of time there are 4 failures, it might be beneficial to repair it if this situation goes on for long enough. One way to do this is to mix the annual charter strategy with the batch repair strategy, having a set time to do maintenance even if the required number of failures is not reached. Since this combination of preventive and corrective maintenance is a common strategy within the literature its absence in this paper is surprising.

\bigskip

%Reference case
In \cite{dinwoodie2015reference} this same group of researchers proposes a reference case for maintenance models. Their idea is for various maintenance models to optimise a constructed scenario a fictional windfarm, as a benchmark to compare these models. This allows us to see which models perform better in various scenarios, as they constructed a base case and a set of variants. In the paper they compare four models, and compare various metrics of the results. For availability of the windfarms all results are extremely close, apart from three scenarios. It is explained that these differences result from previously unknown assumptions in the different models, such as whether  parallel maintenance tasks are possible on the same turbine, and the moment at which tasks should be assigned to vessels. 

This uncovering of assumptions is a strong benefit of using a standardised reference case to verify a model. Seeing that a new model performs similarly to other models apart from certain scenarios can give insight into how this new model handles these scenarios in ways that might otherwise have gone unnoticed, as demonstrated in this paper.

\bigskip

%OG CHECKED: Besnard, Short term stochastic optimisation
In \cite{besnard2011stochastic} a stochasitc optimisation model is constructed for short-term maintenance planning. The primary goal is to utilize times when energy production is expected to be low for maintenance, in order to minimise production losses. An interesting aspect of this model is the build-in uncertainty of weather forecasts. The stochastic element of the model is realized by having a small set of scenarios, and the average cost over all scenarios is minimised. The first time step is assumed to have the correct forecast, hence the idea behind the model is for the optimisation to be recomputed regularly. A rolling horizon approach such as this seems like a good method to deal with these uncertain forecasts, although it can be computationally expensive to recalculate regularly. 

\bigskip

%OG CHECKED: Stalhane, Optimisation focussed on fleet size
Another optimisation model focused on maintenance is given in \cite{staalhane2019optimizing}, where the problem of fleet composition is investigated through a two-stage stochastic programming model. The problem is decomposed using a variant of a Dantzig-Wolfe decomposition. In the first stage the set of vessels to be chartered for each active base is decided, while in the second stage the maintenance tasks are divided over the available vessels. The first stage has an objective function minimising costs, which has one term representing the expected costs from the second stage. This cost depends on the stochastic variables in the second stage (failures, energy generated based on weather conditions, availability of vessels based on weather conditions). In order to solve it, a set of scenarios is generated, each of which represent a realisation of this set of variables. The weighted average costs of all scenarios (weighted on their probability) is used to represent the expected costs, after which the first stage of the problem can be solved. 

This sort of decomposition is potentially useful for my models, to handle the stochastic aspects of the problem. In this paper the model is verified by comparing it to reference cases constructed in \cite{dinwoodie2015reference} which was discussed earlier in this section. The computations are shown to run in feasible time, and when the fleet composition is fixed it is shown to give comparable results to what is expected.

\subsection{Other new knowledge} \label{ss:othnew}
%ONGOING: Updated this after reading (2 paragraphs)
While there is not much research relating specifically to decommission projects, some recent work has still been done in this field. In \cite{irawan2019optimisation} an attempt to optimise the decommissioning is made using an ILP. The model created focuses on minimising total costs, and takes many factors into account, such as both offshore and onshore logistics, components that can be sold and components that can be recycled. This broadness means the model is more accurate, but it also means they were not able to solve the exact problem. For this reason they tried various relaxations, and proposed a matheuristic method in which some integer constraints are relaxed. They use this method to create feasible and well-performing solutions in a short time.

\bigskip

%ONGOING: Added
%TODO: Quote this paper when talking about improvements in an introduction
In the last two decades the the installation time has generally decreased, as analysed in \cite{lacal2018offshore}. This work looks at the installation times of the foundations of a windfarm, the installation times of the turbines, and the overall installation times. It observes a 22\% time decrease per turbine between the periods of 2000 to 2003, and 2016 to 2017. This improvement is more impressive when you consider the distance from the shore has increased in that time. However, the true scale of the improvement only becomes clear when you look at the time per megawatt; this reveals a 71\% time reduction within this timeframe. This is a very substantial reduction, and one that shows the potential of large windfarms with many turbines that are located far off the shore. The specific causes of this improvement are not investigated much, so it is unclear whether this improvement mainly comes from the components used, or the logistics of installation, or some other cause. Investigating this is noted as future research. 

\bigskip

%ONGOING: Updated this paragraph
An overview of the state of robust optimisation is given in \cite{gabrel2014recent}. This study looks at 130 papers, 45 PhD dissertations, and selected other works published between 2007 and 2013 which discussed robust optimisation. The sheer amount of research done reflects the strength of this method. Both the theory and applications of robust optimisation are discussed. The applications include classical logistics problems such as inventory management and scheduling, problems related to finance and revenue management, queueing networks, energy systems and public good (decisions that will benefit the general public). This shows the wide variety of possible applications that RO methods can have. They conclude by highlighting four key developments in RO between 2007 and 2013; (1) the extensive amount of research regarding robustifying stochastic optimization, (2) a link between uncertainty sets and risk theory allows for a connection with decision sciences, (3) new results in the area of sequential decision-making and multi-stage models, and (4) new areas of applications. 

\subsection{Closing thoughts} \label{ss:clotho}
As is hopefully evident from this section, I have worked hard to improve my knowledge where it was lacking before. A key insight I gained from the maintenance papers discussed is how different this phase is, not only in the work that need to be done, but also from a modeling perspective. When scheduling the installation phase which will take roughly 3 years you could (roughly) plan which tasks are performed in which weeks, for the entire project. And each week the project will get closer to completion. With the maintenance phase spanning 20-30 years  this approach is infeasible, and there is no one goal that you progressively move closer to. Instead it has a more cyclic nature where you aim to mitigate the degradation of the windfarm over time, and the tasks that need to be performed cannot be known \emph{a priory}. Therefore smaller timescales, such as rolling horizons covering weeks rather than years, are much more appropriate for this phase. This is an insight that needs to be considered in a model aiming to combine this phase with the other phases. 

\pagebreak

\section{Developing models}\label{s:model}
In the past year I have started developing optimisation models for various scheduling decisions that come up during an OWFs life-cycle. I developed the theory of these models, and implemented and tested them with simple test-cases. This implementation will be discussed in \Cref{s:impl} and this section will talk about the models and the process of creating and improving them. 

I started with very simple models that had a small scope and many assumptions, and progressively added complexity while relaxing the assumptions. This provided me with practice and insights in optimization modeling, a technique I had previously extensively read about but not used myself on any large scale. Therefore this start with simple models was needed, and this approach has made me learn a lot about the nuances in creating these models. 

All models I created are Mixed-Integer Linear Programming (MILP) models, meaning the variables can both be continuous or integer variables, and every variable has a linear relation with the objective and the constraints (i.e. no variables are multiplied by other variables). This is the type of models most commonly used in the scheduling literature I have come across, indicating they are generally well-suited for these this type of problem. 

It is also worth noting that each of the models shown in this section represents a stage in my development as a researcher and as someone designing model. For that reason the models shown, especially the early ones, can likely be refined further. Since this report is about my work and progress I opted to not to go back to my older models and refine them extensively with the experience I gained since making them originally. 

\subsection{Deterministic models}
The first models I worked on were three simple models, one for each of the three phases. My idea behind this was to create a basis for each of the phases, which I could then combine into models where multiple phases are considered. To give the reader an idea of how these models work I will show some of the models I created.

\subsubsection{Installation model}
I first started work on an installation model. This was an iterative development process where the first handful of models had logical contractions or were infeasible for different reasons, and the first feasible models turned out to be missing some crucial restrictions and gave models that would be impossible in practice. The first model that gave potentially possible results, albeit under heavy assumptions, is shown here:

\small
\begin{equation}
	\max_{\substack{O_p, N_{r,p} \in \mathbb{Z}^* \\
	s_{a,i,t} \in \{0, 1\}}} 
	\sum_{p \in P} [ O_p \cdot v_p - \sum_{r \in R} N_{r,p} \cdot C_{r,p} ]
\end{equation}
subject to:
\begin{align}		
s_{a,i,t} \leq& s_{a,i,(t+1)}											&	\forall a \in A, \forall i \in I, \forall t \in T				\\
s_{a,i,(\omega_{i,t_N})} =& 1											&	\forall a \in A, \forall i \in I						\\
s_{a,j,t} \leq& s_{a,i,(\omega_{i,t})}										&	\forall a \in A, \forall (i, j) \in IP, \forall t \in T 			\\
N_{r,p} \geq& \sum_{a \in A}\sum_{i\in I} (\rho_{i,r} \cdot (s_{a,i,t} - s_{a,i,(\omega_{i,t})}))	& 	\forall r \in R, \forall p \in P, \forall t \in T_p			\\
O_p =&  \sum_{a \in A} s_{a,i_N,(\omega_{i_N,t_p})}							& 	\forall p \in P 							\\
N_{r,p} \leq& m_{r,p}												& 	\forall r \in R, \forall p \in P
\end{align}
\normalsize

In the problem for which this model is made there is a set of assets $A$ that each have a set of $I$ tasks that need to be completed within the timeframe. There are two timescales used; periods $p$ which is the timescale at which turbines can be brought online and vessels can be chartered (a month within my artificial test cases) and timesteps $t$ at which tasks are performed (an hour in my test cases). These two different timescales help incorporate the variety of events captured by this model; weather conditions and tasks being completed happens on the scale of hours, but a vessel chartered is chartered for a minimum duration (for example, one month). 

There are three types of decision variables in this model: 

\begin{itemize}
\item $O_p$: integer variable representing how many turbines are online in a given period $p$
\item $N_{r,p}$: integer variable representing how many resources of type $r$ are used in period $p$
\item $s_{a,i,t}$: binary variable which takes a value of 1 if task $i$ on asset $a$ has start at (or before) time $t$
\end{itemize}

The primary decisions that need to be made are the start times of the tasks (the first time steps for each asset $a$ and task $i$ for which $s_{a,i,t}$ takes the value 1); from this the times the turbines come online and the resources required follow directly. 

Equation (1) is the objective; the goal is maximizing the total value of the project. Therefore, per period, we add up the energy value generated ($O_p \cdot v_p$ where $v_p$ is the value of energy that a single turbine generates in that timeframe) and subtract the costs of vessels used ($N_{r,p} \cdot C_{r,p}$ where $C_{r,p}$ is the cost of that type of vessel). It is assumed the values $C_{r,p}$ and $v_p$ are deterministic and given as inputs. If a day-rate for vessels or MWh and energy market rates are given, the values per period can be calculated from that. 

Equation (2) enforces that if a task is started it remains started for every later timestep. Equation 3 uses the time indicator $\omega_{i,t}$ which treated as a parameter; it indicates the timestep at which task $i$ should have been started, for it to have finished at time $t$. It is defined as 
$$\omega_{i,t} = \max\{\tilde{t} | \sum_{x = \tilde{t}}^t \psi_{i,x} \geq d_i, \tilde{t} \in T\}$$ 
where $\psi_{i,t}$ is a binary parameter which is 1 if the weather allows task $i$ to be performed at time $t$, and $d_i$ is the duration of task $i$. In this it is assumed that every task can be started and then halted if the weather turns bad, and continued the moment the weather allows this again (during this entire timeframe the vessels are unavailable to perform other tasks). Since this is a highly simplified model, the weather and duration are assumed to be perfectly predicted, hence $\omega_{i,t}$ is a deterministic value. In equation (3) it uses the value $t_N$ which is the final timestep, hence this equation enforces that every task is started early enough for it to be finished by the final timestep. 

Equation (4) enforces a specific task order; $IP$ is the set of pairs of tasks $(i, j)$ which require task $i$ to be finished before task $j$ is started. In equation (5) the number of vessels needed in a specific period is calculated; $\rho_{i,r}$ is the amount of resources of type $r$ task $i$ needs. This value is counted once for every task started, but every task that finished is subtracted again. This equation uses $T_p$ which is simply the set of timesteps within period $p$. In Equation (6) $i_N$ is the final installation task, and $t_p$ is the deadline (in timesteps) for a turbine to be finished if it is to be active in period $p$ (this can be the first timestep of $p$, but could also be chosen to be earlier if the operator wishes to do so). Equation (6) counts how many assets have finished installation (i.e. completed task $i_N$) in time to be active in period $p$ (before time step $t_p$); the term $\omega_{i_N,t_p}$ is the timestep at which the final installation task should have been started for it to be completed by the deadline $t_p$. Finally equation (7) puts a maximum on the number of vessels of a specific type used in a given period, where $m_rp$ is an input parameter. Without this the model might decide to charter 100 heavy lift vessels in the first period and work on all turbines simultaneously, which is unrealistic in practice. 

\bigskip

The above model can be used to optimize the installation project, under some severe assumptions. It is assumed that the precise weather is known for the entire project (which can often span years), assumes no delay in tasks other than that based on weather, and assumes every turbine is active at full strength without any failures from the moment it is completed. This said, creating this model was valuable practice for me, as the steps it took me to get to this model taught me more aspects to pay attention to. 

\subsubsection{Maintenance model}
The maintenance model is very similar in structure; it assumes that an asset will fail if it is not maintained for some predetermined time. Under these assumptions the maintenance models had a set amount of minimum maintenance tasks that should be performed, and a set of optional tasks that can be performed to increase uptime:

\begin{equation}
	\max_{\substack{O_t, N_{r,p} \in \mathbb{Z}^* \\ 
	s_{a,i,t}, b_{a,t} \in \{0, 1\}}} 
	\sum_{p \in P} [ DIS^p (\sum_{t\in T_p} (O_t \cdot v_t)  - \sum_{r\in R} (N_{r,p} \cdot C_{r,p})) ]
\end{equation}
subject to:
\begin{align}
s_{a,i,t} \leq& s_{a,i,(t+1)}												&	\forall a \in A, \forall i \in M, \forall t \in T	\\
s_{a,i,(\omega_{i,t_N})} =& 1												&	\forall a \in A, \forall i \in M^M			\\		
N_{r,p} \geq& \sum_{a\in A} \sum_{i\in M} (\rho_{i,r} \cdot (s_{a,i,t} - s_{a,i,(\omega{i,t})})) 		& 	\forall r \in R, \forall p \in P, \forall t \in T_p 	\\
b_{a,t} >&  \sum_{i \in M} [s_{a,i,(\omega_{i,(t - \lambda_a)})} - s_{a,i,(\omega_{i,t})}]			&	\forall a \in A, \forall t \in T 			\\
O_t =&  |A| - \sum_{a \in A} b_{a,t}											&	\forall t \in T 						\\
N_{r,p} \leq& m_{r,p}													&	\forall r \in R, \forall p \in P
\end{align}

The objective function is similar to that of the installation model, with two changes. It adds a discount factor $DIS$ which can be used to discount income and costs later in the project, if the operator would wish to do so. Additionally the terms regarding online turbines and the energy value now depend on the timestep rather than period, as during maintenance they can be brought online or offline more often and on smaller timescales. 

Equation (9) is identical to equation (2) from the installation model, other than that the set of tasks is now called $M$ rather than $I$. This set $M$ is made up of two distinct subsets: $M^M$ and $M^O$, which respectively contain the mandatory and optional tasks. The idea behind this is $M^M$ contains some minimum required maintenance, for example if the maintenance project spans 20 years and the operator wants at least one routine inspection to be done every year, $M^M$ would contain 20 inspection tasks, and $M^O$ contains any other tasks. Looking back at this approach, it is clear that the model would not guarantee these mandatory tasks to be equally spread out. The way failures are modeled (which I will discuss later) helps to mitigate that, but I expect an operator would prefer to have some guarantee that these 20 inspection tasks do not all happen in the first 5 years. 

Equation (10) enforces all mandatory tasks to be finished by the end of the considered timespan, and equation (11) is identical to (5) from the previous model. 

A new variable is introduced in (12); $b_{a,t}$ is a binary variable which takes a value of 1 if asset $a$ is broken at time $t$. We have a parameter $\lambda_a$ which indicates the amount of time an asset can go without maintenance before failing. In the equation we add up all maintenance tasks that have finished more than $\lambda_a$ timesteps ago, and subtract all tasks that have finished now. If these amounts are equal, $b_{a,t}$ is set at 1. 

Finally equation (13) determines how many assets are online by subtracting the amount of broken assets from the total number, and equation (14) is identical to (7). 

\bigskip

Based on the way this model handles failures and the set of tasks available, we could reframe the problem and say it only handles planned maintenance, and not responsive maintenance. Planned maintenance is all the maintenance that happens at predetermined moments, while responsive maintenance is that which happens in response to failures or condition-monitoring data. This distinction may seem similar to the distinction between preventive and corrective maintenance made in some papers in \Cref{s:know}, but that distinction focuses on whether the maintenance happens before or after failure, which is a different metric since maintenance that happens based on condition-monitoring before any failure occurs is preventive but not planned. 

If we reframe the problem in this way, $\lambda_a$ is a predetermined amount of time after maintenance after which the chance of a failure exceeds some threshold; from this moment the turbines energy is not longer included in the objective function as the chance of failure is deemed too high. $M^M$ would still represent some minimum amount of maintenance, and $M^M \cup M^O$ represents the maximum amount of planned maintenance. With this reframing the model could be used to schedule all planned maintenance, while a separate model and strategy would have to be determined for responsive maintenance. 

\subsubsection{Decommission model}
The initial decommission model is nearly identical to the previously shown installation model:

\small
\begin{equation}
	\max_{\substack{N_{r,p} \in \mathbb{Z}^* \\
	s_{a,i,t} \in \{0, 1\}}} 
	\sum_{p \in P} [ DIS^p (\sum_{t\in T_p} \sum_{a \in A} ((1 - s_{a,i_0,t}) \cdot v_t)  - \sum_{r\in R} (N_{r,p} \cdot C_{r,p})) ]
\end{equation}
subject to:
\begin{align}		
s_{a,i,t} \leq& s_{a,i,(t+1)}											&	\forall a \in A, \forall i \in I, \forall t \in T				\\
s_{a,i,(\omega_{i,t_N})} =& 1											&	\forall a \in A, \forall i \in I						\\
s_{a,j,t} \leq& s_{a,i,(\omega_{i,t})}										&	\forall a \in A, \forall (i, j) \in IP, \forall t \in T 			\\
N_{r,p} \geq& \sum_{a \in A}\sum_{i\in I} (\rho_{i,r} \cdot (s_{a,i,t} - s_{a,i,(\omega_{i,t})}))	& 	\forall r \in R, \forall p \in P, \forall t \in T_p			\\
N_{r,p} \leq& m_{r,p}												& 	\forall r \in R, \forall p \in P
\end{align}
\normalsize

The only difference is the absence of the $O_p$ variables and constaints related to it, and the objective function. It adds a discount factor $DIS$, as in the maintenance model, and sees if decommission has started at any particular time with variable $s_{a,i_0,t}$, where $i_0$ is the first decommission task (after which a turbine is offline).

\subsubsection{Combined model} \label{sss:comb}

After creating these models I combined them into one model spanning the entire life-cycle, planning every single task (under the same deterministic assumptions).

\small
\begin{equation}
	\max_{\substack{N_{r,p} \in \mathbb{Z}^* \\ 
	s_{a,i,t}, o_{a,t} \in \{0, 1\}}} 
	\sum_{p \in P} [ DIS^p (\sum_{t\in T_p} \sum_{a \in A} (o_{a,t} \cdot v_t)  - \sum_{r\in R} (N_{r,p} \cdot C_{r,p})) ]
\end{equation}
subject to:
\begin{align}
s_{a,i,t} \leq& s_{a,i,(t+1)}															& \forall a \in A, \forall i \in \mathcal{I}, \forall t \in T		\\
s_{a,i,(\omega_{i,t_N})} =& 1															& \forall a \in A, \forall i \in \mathcal{I} - M^O			\\
s_{a,i^D_0,t} - 1 \leq& s_{a,i,(\omega_{i,t})} - s_{a,i,t}											& \forall a \in A, \forall i \in \mathcal{I} - D, \forall t \in T	\\
s_{a,j,t} \leq& s_{a,i,(\omega_{i,t})}														& \forall a \in A, \forall (i, j) \in IP, \forall t \in T 		\\
N_{r,p} \geq& \sum_{a\in A} \sum_{i\in \mathcal{I}} (\rho_{i,r} \cdot (s_{a,i,t} - s_{a,i,(\omega_{i,t})})) 				& \forall r \in R, \forall p \in P, \forall t \in T_p 			\\
N_{r,p} \leq& m_{r,p}																& \forall r \in R, \forall p \in P 					\\
o_{a,t} \leq& s_{a,i^I_N,(\omega_{i^I_N,t})} - s_{a,i^D_0,t}										& \forall a \in A, \forall t \in T					\\
o_{a,t} \leq& \sum_{i \in M \cup \{i^I_N\}} (s_{a,i,(\omega_{i,t})} - s_{a,i,(\omega_{i,(t-\lambda_a)})})				& \forall a \in A, \forall t \in T					\\
o_{a,t} \leq& 1 + s_{a,i,(\omega_{i,t})} - s_{a,i,t}												& \forall a \in A, \forall i \in M, \forall t \in T			
\end{align}
\normalsize

For the most part this model is a combination of the previously shown models. It uses new variables $o_{a,t}$, which is a binary variable per asset and timestep indicating whether that asset is online at the given time. In order for it to be online that asset needs to be fully installed and not started decommission (equation (28)), have had recent maintenance (equation (29)) and no maintenance on at asset can be happening at this time (equation (30)). The value of these variables follows directly from the scheduling decisions, but I introduced the auxiliary variable for clarity. In these equations $i^I_N$ indicates the final installation task and $i^D_0$ indicates the first decommission task. In the objective function this new variable is used to calculate the total value of energy generated. Equation (24) ensures only decommission tasks are allowed to be performed after decommissioning has started. All other equations are taken directly from the installation model, with the only difference that the set $\mathcal{I}$ is the set of all tasks and $D$ is a subset containing all decommission tasks. 

This model still assumes deterministic weather which limits its practical usability, but even if this limitation is acceptable it will still be computationally challenging to find an optimal solution for a schedule spanning two or three decades, which would be the common duration of the full lifespan for which the model is designed. To illustrate, take a windfarm with 80 assets, each of which need 40 tasks to be scheduled over the course of its lifespan. If this lifespan is 20 years and the timesteps are chosen to be 1 hour, this results in 175.000 timesteps, and over half a billion $s_{a,i,t}$ variables, which would be difficult to solve to optimality. Additionally the uses of scheduling every single task over the course of 20 years are limited. 

However, these three phases tend to be treated completely separately within the literature, which also has strong drawbacks. A goal of this research is to find a middle ground that balances the drawbacks of both approaches, and the above model is a step in that process. Even if the direct practical uses of this model are limited, it was still a good exercise for me to work on. I would not have some of the insights above if I had not created a (simplified) model spanning the entire life-cycle, and experimenting with the size of model (in number of variables and constraints) gave me a better idea of how quickly models such as this can grow in size. 

\subsection{Stochastic model} \label{ss:stoc}
After working my way up to the previously discussed life-cycle spanning model, I aimed to relax the assumptions in it, first and foremost the assumption that every aspect is deterministic. This proved difficult for various reasons. I started with the model shown in \Cref{sss:comb}, which is a fairly complicated model already. Since I do not have much experience with Stochastic Programming models, starting with a complicated model such as this was challenging. The model also spans a large timescale, but still has a high fidelity (if a timestep is still assumed to be an hour). 

In the models shown before the parameter $\omega_{i,t}$ was used to incorporate weather circumstances, and this parameter was used as a variable index. This approach is not well suited for Stochastic Programming, as this $\omega_{i,t}$ would be subject to uncertainty, which means the variables involved are also subject to uncertainty. I tried to handle this issue by introducing scenarios, a technique used in the literature \cite{besnard2011stochastic,de2012computational}. Each scenario represents a realization of all uncertain factors, and the model would be optimized over a set of (selected) scenarios. In this example a new index would be introduced to $\omega_{i,t}$, say $\omega_{i,t,s}$, where $s$ is the scenario index. However this approach is more suited to shorter timescales than the ones I was using; only a handful of scenarios are needed to capture the possible weather conditions over the course of a week or a month, but over the course of 20 years many scenarios are needed to make the set representative of the possible options. Therefore I opted to scale down and introduce stochastic elements in a smaller model first.

For this I chose to focus on the maintenance phase, introducing stochastic failures and energy values:

\begin{minipage}{\textwidth}
\begin{adjustwidth}{-3cm}{-2.5cm}

\begin{equation}
	\max_{\substack{N_{r,p} \in \mathbb{Z}^* \\ 
	s^P_{a,i,t}, s^R_{a,i,t,\sigma}, o_{a,t,\sigma} \in \{0, 1\}}} 
	\sum_{\sigma \in S} \sum_{p \in P} [ DIS^p (\sum_{t\in T_p} \sum_{a \in A} (o_{a,t,\sigma} \cdot v_{t,\sigma})  - \sum_{r\in R} (N_{r,p} \cdot C_{r,p})) ]
\end{equation}
subject to:
\begin{align}
s^P_{a,i,t} \leq& s^P_{a,i,(t+1)}													& \forall a \in A, \forall i \in M^P, \forall t \in T				\\
s^R_{a,i,t,\sigma} \leq& s^R_{a,i,(t+1),\sigma}											& \forall a \in A, \forall i \in M^R, \forall t \in T, \forall \sigma \in S	\\
s^P_{a,i,(\omega_{i.t_N})} =& 1													& \forall a \in A, \forall i \in M^P						\\
N_{r,p} \geq& \begin{cases} \sum_{a\in A} ( \sum_{i\in M^P} (\rho_{i,r} \cdot (s^P_{a,i,t} - s^P_{a,i,(\omega_{i,t})})) \\
+ \sum_{i \in M^R}  (\rho_{i,r} \cdot (s^R_{a,i,t,\sigma} - s^R_{a,i,(\omega_{i,t}),\sigma}))) \end{cases}		& \forall r \in R, \forall p \in P, \forall t \in T_p, \forall \sigma \in S	\\
N_{r,p} \leq& m_{r,p}															& \forall r \in R, \forall p \in P 						\\
o_{a,t,\sigma} \leq& \begin{cases}\sum_{i \in M^P} (s^P_{a,i,(\omega_{i,t})} - s^P_{a,i,(\omega_{i,(t-\lambda_{a,i,\sigma})})}) 									\\
+ \sum_{i \in M^R} (s^R_{a,i,(\omega_{i,t}),\sigma} - s^R_{a,i,(\omega_{i,(t-\lambda_{a,i,\sigma})})\sigma}) \end{cases}	
																		& \forall a \in A, \forall t \in T, \forall \sigma \in S			\\
s^R_{a,i,t} - s^R_{a,i,(t-1)} \leq& \begin{cases} 1 - \frac{1}{L} \cdot (\sum_{j \in M^P} (s^P_{a,j,(\omega_{j,t})} - s^P_{a,j,(\omega_{j,(t-\lambda_{a,j,\sigma})})}) 			\\ 
+ \sum_{j \in M^R} (s^R_{a,j,(\omega_{j,t}),\sigma} - s^R_{a,j,(\omega_{j,(t-\lambda_{a,j,\sigma})})\sigma}))\end{cases}	
																		& \forall a \in A, \forall i \in M^R, \forall t \in T, \forall \sigma \in S	\\
o_{a,t,\sigma} \leq& 1 + s^P_{a,i,(\omega_{i,t})} - s^P_{a,i,t}									& \forall a \in A, \forall i \in M^P, \forall t \in T, \forall \sigma \in S 	\\
o_{a,t,\sigma} \leq& 1 + s^R_{a,i,(\omega_{i,t}),\sigma} - s^R_{a,i,t,\sigma}							& \forall a \in A, \forall i \in M^R, \forall t \in T, \forall \sigma \in S
\end{align}

\end{adjustwidth}
\end{minipage}

\bigskip

This model is still based on the previous models, and it introduces a set of scenarios $S$, and every scenario $\sigma \in S$ is a realization of the stochastic failures and energy values. What this model does is split the $s_{a,i,t}$ variables from the previous models in two groups, $s^P_{a,i,t}$ and $s^R_{a,i,t,\sigma}$, which represent planned and responsive maintenance tasks respectively. The $s^P_{a,i,t}$ variables function exactly like before, and $s^R_{a,i,t,\sigma}$ do the same but depend on a scenario. In the same way the variables $o_{a,t,\sigma}$ now depend on the scenario. In this way, the failure state $o_{a,t,\sigma}$ and responsive tasks $s^R_{a,i,t,\sigma}$ are solved for every scenario separately, but the planned tasks $s^P_{a,i,t}$ and vessel charters $N_{r,p}$ have to be planned in advance and are the same for every scenario. 

The only really new equation is (38); it is meant to ensure that responsive tasks only happen after a failure. The left hand side takes a value of 1 only if that the corresponding task started at timestep $t$, and the right hand side is 1 unless a task has recently been completed on the asset. How recently is determined by $\lambda_{a,i,\sigma}$ which is the time after task $i$ is completed at which asset $a$ fails in scenario $\sigma$. These variables for all tasks are summed up in the same way as was done in equation (29), where the sum is equal to the number of tasks completed recently enough. The $L$ in this equation is a large number, at least $|M^P \cup M^R|$, to ensure the right hand side never goes negative. 

Equations (32) and (33) are the same as equation (22), this time split for the planned and responsive tasks respectively; the same happened with equations (39) and (40) which both come from (30). Equations (34) and (36) are equal to (23) and (27) respectively. In equations (35) and (37) the task summation is split in two parts for the two types of task, but apart from that they are directly taken from (26) and (29) respectively. 

\bigskip

The strength of this model is that it can be used to plan decisions that need to be made in advance (which vessels to charter and when to schedule certain routine tasks) while considering a set of uncertain scenarios. However it does still assume complete \textit{a priori} knowledge of each of these uncertain factors, as well as the weather. Since the focus lies on the decisions universal to all scenarios, rather than any specific scenario, this might not pose an issue for some uses. The model could potentially be improved by letting the weather conditions (encompassed in $\omega_{i,t}$) also depend on the scenario. The reason I have not done that (yet) is that while developing these models, I have been implementing at the same time, as discussed in detail in \Cref{s:impl}. The implementation of the above model already had issues being solved on my computer with a very small test case, and I wanted to improve that before making it even more complex. 

\subsection{Multilevel model}
The above model grew in complexity with every iteration, and since I had reached a point where the implementation could not even solve a very simple testcase in a number of hours (on my personal computer) I attempted a different approach. In the literature multilevel models are common, and splitting the problem into multiple subproblems can reduce the time it takes to solve. My idea behind this model was one level in which large scale decisions are made, such as for which tasks to complete and which vessels to charter for every month. Then a lower level can assign these tasks to specific vessels in some order. 

At the time of writing this model exists in a preliminary form, but it has not been completely tested yet, and there may still be improvements to be made. There are still some aspects of the model that I have not fully decided on, and in this report I will try to explain those aspects. The higher level model I came up with is shown here:

\begin{equation}
	\min_{\substack{N_{y,m,\sigma}, P_m, R_{m,\sigma} \in \mathbb{Z}^* \\
	\gamma_\sigma \in \mathbb{R}_{\geq 0} \\
	h_{m,\sigma} \in \{0, 1\} }}
	\begin{aligned}
	\frac{1}{|S|} \cdot \sum_{\sigma \in S} ( \sum_{m \in M} [\sum_{y \in Y} 
	(N_{y,m,\sigma} \cdot c_{y,m}) +  
	P_m \cdot d_P \cdot e^H_m + \\
	\sum_{m' = 0}^{m} (f_{m',\sigma} - R_{m',\sigma}) \cdot e^H_m \cdot H_m ]
	- u \cdot \gamma_\sigma)
	\end{aligned}	
\end{equation}
subject to:
\begin{align}
l_y \cdot N_{y,m,\sigma} 			&\geq 	\begin{cases} P_m \cdot d^P_y + R_{m,\sigma} \cdot d^R_y \\
								+ \gamma_\sigma - h_{m,\sigma} \cdot L \end{cases}
																				& \forall \sigma \in S, \forall m \in M, \forall y \in Y 	\\
1 						&\geq		h_{y,m,\sigma} + \frac{P_m + R_{m,\sigma}}{L}					& \forall \sigma \in S, \forall m \in M 		 	\\
\sum_{m' = 0}^{m-1} f_{m',\sigma}	&\geq 	\sum_{m' = 0}^m R_{m',\sigma}								& \forall \sigma \in S, \forall m \in M			\\
\sum_{m\in M} P_m 			&\geq 	A 												&						
\end{align}

Keep in mind that where every previously shown model used similar notation, this model was started from scratch, and uses a lot of new notation. 

There are three primary types of decision variables used in this model:

\begin{itemize}
\item $N_{y,m,\sigma}$: The amount of resources (vessels) of type $y$ chartered in month $m$ in scenario $\sigma$
\item $P_m$: The amount of planned maintenance tasks in month $m$
\item $R_{m,\sigma}$: The amount of responsive maintenance tasks in month $m$ in scenario $\sigma$
\end{itemize}

For the purposes of this model it is assumed there is only one type of planned task, and one type of responsive task. This means that the durations and required vessels are uniform. This assumption could be relaxed, but as my goal with this model was to try out a new, easier to solve, approach before complicating it more. 

There are two other types variables in the model, $\gamma_\sigma$ and $h_{m,\sigma}$. The latter is simply a set of helper variables to make the constraints work linearly which will be explained later, but the former type of variable represents a buffer in the capacity. In this model a set of chartered vessels and a set of tasks is decided for each month. Each vessel has a capacity, such as the amount of hours it can work in a month, and each task has a duration. There will usually be months where the full capacity is not used, but this can be good for robustness. These spare hours can be used in case of a delay, and we call it a buffer. For a scenario, $\gamma_\sigma$ is the minimum buffer over all months within that scenario, and it is included in the objective function to encourage a higher buffer. This should lead to tasks being spread over the months, and will ideally create a robust schedule in which no vessel is busy every hour in a given month. 

The objective function (41) uses the following parameters:

\begin{itemize}
\item $c_{y,m}$: The cost of chartering vessel type $y$ in month $m$
\item $d_P$: The duration of a planned task 
\item $e^H_m$: The average value of energy generated by a single turbine in an hour, in a given month $m$
\item $f_{m,\sigma}$: The amount of failures in month $m$ and scenario $\sigma$
\item $H_m$: The the amount of hours in month $m$
\item $u$: A parameter that sets the value per hour of buffer
\end{itemize}

The parameter $u$ can be adjusted based on the operators wishes; the higher it is, the higher buffers are prioritized over minimizing expected costs. An appropriate value for a given situation will likely have to be found through experiments. 

In the objective function an average is taken over all scenarios, which counts the costs made through vessel charter ($(N_{y,m,\sigma} \cdot c_{y,m})$), value of energy missed due to downtime during planned maintenance ($P_m \cdot d_P \cdot e^H_m$), value of energy missed due to failures that are not yet repaired ($\sum_{m' = 0}^{m} (f_{m',\sigma} - R_{m',\sigma}) \cdot e^H_m \cdot H_m$), and the discount for the size of the buffer ($- u \cdot \gamma_\sigma$). These are approximations, as energy values can fluctuate per hour and an average is used, and failures are assumed to cost a full month worth of energy. Since a failure can occur at any point in the month, and be repaired at any point in a later month, this seems like a reasonable assumption for an approximation. This model focuses on high-level decisions, so approximations of the cost are sufficient. 

Equation (42) is the capacity constraint; $l_y$ is the capacity (available hours) of a single vessel, and $d^P_y$ and $d^R_y$ are the durations for which planned and responsive tasks require a vessel of type $y$. The variable $h_{m,\sigma}$ is binary and can take the value of 1 if and only if no tasks are planned in month $m$ in scenario $\sigma$, which is enforced by the constraint in equation (43). In both of these equations $L$ is a large number. This extra variable is required in case there are months in which no tasks are planned and no vessels are chartered; in this situation the left hand side of equation (42) is equal to 0, and there could be no buffer without this extra term.

In equation (44) it is enforced that there can never be more repairs than there were failures at the end of the previous month, and in equation (45) a minimum amount of planned tasks is set to be carried out over the planning horizon. If $A$ is set as the amount of assets, every asset would be maintained once within this horizon. 

\bigskip

This above model can be used to plan high-level decisions, in a similar way the model in \Cref{ss:stoc} can. However since the level of detail is much lower, the resulting problem will be smaller and faster to solve. The drawback may also be reduced accuracy, but in order to determine whether that is the case computational experiments will have to be done. 

When a solution to the above model has been found, there is one remaining problem; for any given month, which vessel will do which tasks in what order. In order to solve this the following lower-level model can be solved for every month:

\begin{adjustwidth}{-2.5cm}{-2.5cm}
\begin{equation}
	\min_{\substack{s_i \in \mathbb{R}_{\geq 0} \\ 
	a_{v,i,j} \in \{0, 1\}}} 
	\sum_{i \in I} c_i \cdot (s_i + \max_{y \in Y} (s_{y,i}+ d_{y,i}))
\end{equation}
subject to:
\begin{align}
\sum_{i \in I} a_{v,i,j}						&\leq 		1							& \forall v \in V, \forall j \in J 						\\
\sum_{i \in I} a_{v,i,j}						&\leq 		\sum_{i \in I} a_{v,i,(j-1)}				& \forall v \in V, \forall j \in J - \{ 0 \}					\\
\rho_{y,i}								&\leq	 	\sum_{v \in V_y} \sum_{j \in J} a_{v,i,j} 	& \forall y \in Y, \forall i \in I						\\
s_i + \max_{y \in Y} (s_{y,i}+ d_{y,i})				&\leq		T 							&\forall i \in I 								\\	
\begin{aligned} L \cdot (a_{v,i,j} + a_{v,i',(j-1)}) + \\ 
d_{y,i'} \cdot a_{v,i',(j-1)} - 2L \end{aligned}			&\leq	 	s_i + s_{y,i} - s_{i'} - s_{i',y}			& \begin{aligned} \forall y \in Y, \forall v \in V_y, 			\\
																		\forall i, i' \in I, \forall j \in J - \{ 0 \}	\end{aligned}		
\end{align}
\end{adjustwidth}

This model has two types of decision variables:

\begin{itemize}
\item $s_i$: The starting time of task $i$
\item $a_{v,i,j}$: A binary variable indicating whether vessel $v$ has task $i$ as its $j$-th task
\end{itemize}

Through deciding these variables every task will be assigned to a vessel in a specific order, and each task will have a starting time. In addition to the set of vessel types $Y$ we had in the high-level model we now also have a set of specific vessels $V$, which can be divided into distinct sets $V_y$ based on vessel type. For every task, the amount of vessels of type $y$ needed is called $\rho_{y,i}$. In addition to the starting time $s_i$ that every task has, there may be a delay before the vessel(s) of type $y$ are required, this delay is called $s_{y,i}$. For example, if a task needs a Crew Transfer Vessel from the start but a Heavy Lift Vessel after 3 time units, it would have $s_{CTV,i} = 0$ and $ s_{HLV,i} = 3$. It is assumed that if a task requires multiple vessels of the same type, each of these is needed from the same time, and for the entire duration $d_{y,i}$ without breaks. Finally every task has a cost per time unit $c_i$ in which it is not completed; for reparation tasks this would be equal to the value of energy generated per time unit, while for routine checkups this cost could be 0 (which would mean these tasks will generally be done last). 

The objective is to minimize the cost over all tasks. The term $\max_{y \in Y} (s_{y,i}+ d_{y,i}$ is a constant which indicated the total duration of the task, and it could be removed without affecting the solution. However it is included to have the objective value better reflect the actual costs of the schedule. 

Equation (47) ensures every vessel has at most 1 task assigned as its $j$-th task, for every $j$, and equation (48) enforces a $(j-1)$-th task to be assigned if a $j$-th task is assigned. Equation (49) makes sure every task has sufficient vessels assigned to it, and (50) uses the same constant term the objective function does to ensure every task is finished before the finish time $T$. 

Equation (51) is used to ensure the starting times of consecutive tasks are far enough apart. $L$ is again a large number, which ensures that the left hand side is a large negative number unless  $a_{v,i,j} + a_{v,i',(j-1)} = 2$, i.e. task $i'$ is the $(j-1)$-th task assigned to vessel $v$ and task $i$ is its $j$-th task. If this is the case the $L$ terms cancel out and left hand side becomes equation to the duration for which $v \in V_y$ is needed. The right hand side is equal to the time at which the vessel is needed at task $i$ ($s_i + s_{y,i}$) from which its starting time at task $i'$ ($s_{i'} + s_{y,i'}$) is subtracted. 

\bigskip

This is a fairly straightforward model (compared to the other models shown) as it is meant to only schedule task in a short timespan (a month) and many impactful decisions have already been made in the high-level model. The largest drawback of this model is the speed at which it grows based on the number of tasks. As $|J|$ is the maximum amount of tasks that can be assigned to a single vessel, $|J|$ will likely have to be equal to $|I|$. This would mean the amount of $a_{v,i,j}$ variables grows quadratically with the amount of tasks, and the amount of constraints resulting from equation (51) grows cubically with the number of tasks. 

The model could potentially be expanded by adding a more sophisticated cost function (which takes into account downtime costs for routine maintenance tasks), making durations stochastic, or by adding a robustness measure (a buffer variable similar to $\gamma_\sigma$ in the high level model can be added to equation (51)). As I have not yet fully implemented this multilevel model these improvements might happen later on in my research, depending on the initial implementation results. These results are also required to properly reflect on these two levels of the multilevel model; potentially a stronger link can be used between the two levels but at this point in time I am unable to make any definitive statement on this. 

\pagebreak

\section{Implementation}\label{s:impl}
Lorem Ipsum 

\pagebreak

\section{Additional activities} \label{s:addit} %COWORK course and teaching
In addition to the work directly related to my PhD project, I have participated in some courses. 

I was supposed to take part in the NATCOR course Convex Optimization, to be held at the University of Edinburgh in June 2020. However, due to the Covid-19 pandemic this course was canceled. I was also enrolled in the NATCOR course Forecasting and Predictive Analytics, which was to be held in September 2020 at Lancaster University. This course, due the same pandemic, has been postponed to February 2021. 

\bigskip

While those courses not taking place as planned was disappointing, another course I did not originally plan to go to had to move entirely online, making it possible for me to follow it. The course in question was CO@Work (Combinatorial Optimization at work), hosted by the University of Berlin. This two-week course offered lectures (via Youtube) on varying topics, and exercise and Q\&A sessions (via Zoom). Since the Zoom sessions took place at inconvenient times (due to timezones), I primarily partook in the lectures. The course was aimed at a wide variety of students, ranging from undergraduates new to optimization, to PhD students like myself. This meant that some lectures went over material I am already familiar with, like the workings of the simplex algorithm. Other material focused on techniques to help with solving linear and mixed-integer programs, such as column generation and branch-and-bound techniques. While I had previously been taught how these methods work, this was years ago, and the refresher was quite helpful. The course also had more time to go into details on these techniques, so I certainly learned new aspects of these techniques. Finally there were some corporate talks, at which various companies within the optimization industry talked about what they do and what a career with them could look like. While some of these talks seemed very specific to the company hosting it and less interesting, some also simply talked about work and careers as optimizers in general, which I found very helpful and interesting. 

Generally I am glad I got to follow this course, and the format of having a few hours of lectures to watch at my own pace helped lower the workload (compared to traveling to Berlin for two weeks). This allowed me to still work on my own project during this course, and since the lectures were recorded videos rather than live, I could rewatch the parts that were most interesting or most complex. That said, I did miss the social aspect of this course, as normally with courses such as this you get to spend a week or two with students from all over the world who all study subjects similar to my own. This dimension was entirely missing, which is of course a strong drawback. 

\bigskip

Apart from following courses, I have also helped teach a course. The course, Information Access \& Mining (CS412), was a 4th year Computer Science course focusing on data analysis through machine learning. This is fairly far removed from the topic of my own project, but I was still fairly able to teach the course because of my Computer Science background. The main thing that was new for me was the Python language used in the course, with which I was previously unfamiliar. However, this simply meant that in addition to the teaching experience I got from teaching this course, I also made myself acquainted with Python, which turned out to be a relatively easy language to learn. I lead the labs, which meant I had to answer students questions regarding their exercises. Since I prepared the labs well, answering these questions was fairly straightforward. Additionally I had to mark the exercises, which took the majority of my time spend. But since I was provided with an decently detailed answer key, this was not very difficult either. After the labs stopped (due to the Covid-19 pandemic) my work solely consisted of the marking, lowering the workload. 

This was my first real teaching experience, and I think it went very well. I enjoyed helping the students, and I enjoyed expanding my own knowledge of both the programming language and the subject matter. If I get another chance to help out with a course that interests me during my PhD, I will likely take it.

\pagebreak

\section{Next steps}\label{s:next}
Lorem Ipsum 

\subsection{Timeline}
Lorem Ipsum 

\pagebreak

\bibliographystyle{agsm}
\bibliography{mybib}

\end{document}